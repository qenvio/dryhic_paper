\PassOptionsToPackage{utf8}{inputenc}
\documentclass{bioinfo}
\copyrightyear{2017} \pubyear{2017}

\access{Advance Access Publication Date: Day Month Year}
\appnotes{Original Article}

\begin{document}
\firstpage{1}

\subtitle{Genome Analysis}

\title[OneD]{OneD: increasing reproducibility of Hi-C Samples with
abnormal karyotypes}

\author[Vidal \textit{et~al}.]{Enrique Vidal\,$^{\text{\sfb 1,2}*}$,
François le Dily\,$^{\text{\sfb 1,2}}$, Javier Quilez\,$^{\text{\sfb
1,2}}$, Ralph Stadhouders\,$^{\text{\sfb 1,2}}$, Yasmina
Cuartero\,$^{\text{\sfb 1,2}}$, Miguel Beato\,$^{\text{\sfb 1,2}}$ and
Guillaume Fillion\,$^{\text{\sfb 1,2}}$}

\address{$^{\text{\sf 1}}$Gene Regulation, Stem Cells and Cancer Program,
Centre for Genomic Regulation (CRG), The Barcelona Institute of Science
and Technology (BIST), Barcelona, Spain \\
$^{\text{\sf 2}}$Universitat Pompeu Fabra (UPF), Barcelona, Spain}

\corresp{$^\ast$To whom correspondence should be addressed.}

\history{Received on XXXXX; revised on XXXXX; accepted on XXXXX}

\editor{Associate Editor: XXXXXXX}

\abstract{
  \textbf{Motivation:} The three-dimensional conformation of genomes is an
essential component of their biological activity. The advent of the Hi-C
technology enabled an unprecedented advance in our understanding of genome
structures. However, Hi-C is subject to systematic biases that can
compromise downstream analyses. Several strategies have been proposed to
remove those biases, but none of them addresses the common issue of
abnormal karyotypes. Many experiments are performed in cancer cell lines,
which typically harbor large-scale copy number variations that create
visible defects on the raw Hi-C maps. The consequences of these widespread
artifacts on the normalized maps are mostly unexplored.\\
	\textbf{Results:}
We observed that current normalization methods perform badly in the
presence of large-scale copy number variations, obscuring biological
viarations and enhancing batch effects. To address this issue, we
developed an alternative appoach designed to take into account chromosomal
abnormalities. The method, called OneD, increases reproducibility among
replicates of Hi-C samples with abnormal karyotype, thus significantly
outperforming previous methods.  In the absence of chromosomal
aberrantions, OneD fared equally well as state-of-the-art methods, making
it a safe choice for Hi-C normalization. OneD is fast and scales well in
terms of computing resources for resolutions up to 1 kbp.\\	
\textbf{Availability:} OneD is implemented as an R package available at
\href{http://www.github.com/qenvio/dryhic}
{http://www.github.com/qenvio/dryhic}.\\	
textbf{Contact:} \href{enrique.vidal@crg.eu}{enrique.vidal@crg.eu}\\	
textbf{Supplementary information:} Supplementary data are available at
\textit{Bioinformatics}	online.}



\maketitle



\section{Introduction}

One of the crown achievements of modern biology was to realize that
genomes have an underlying three-dimensional structure contributing to
their activity \citep{rowley2016three}. In mammals, this organization
plays a key role in guiding enhancer-promoter contacts (CITE), in V(D)J
recombination (CITE) and in X chromosome inactivation (CITE). One of the
most significant breakthroughs towards this insight was the development of
the high throughput chromosomal conformation capture technology (Hi-C),
assaying chromosomal contacts at a genome-wide scale
\citep{lieberman2009comprehensive}. Nowadays, exploring the spatial
organization of chromatin has become a priority in many fields and
Hi-C has become part of the standard molecular biology toolbox (CITE).

Contrary to the precursor technologies 3C, 4C and 5C \citep{de2012decade},
Hi-C interrogates all possible pairwise interactions between restriction
fragments. However, this does not guarantee that the method has no bias.
On the contrary, local genome features such as the G+C content, the
availability of restriction enzyme sites and the mappability of the
sequencing reads have been shown to impact the results
\citep{yaffe2011probabilistic}. In addition, the general experimental
biases such as batch effects and protocol variation also apply. It is thus
important to normalize Hi-C data in order to remove biases and artifacts,
so that they are not confused with biological signal.

Several methods have been proposed to remove biases in Hi-C experiments
\citep{schmitt2016genome}. The first strategy is to model biases
explicitly from a defined set of local genomic features, such as the G+C
content and the availability of restriction sites. This approach is used
in the method of \cite{yaffe2011probabilistic} and in Hicnorm by
\cite{hu2012hicnorm}. The second strategy is to implicitly correct
unknown biases by enforcing some regularity on the data. This approach is
used in the ICE method of \cite{imakaev2012iterative}, where the total
amount of contacts of every bin is imposed to be the same. ICE is
currently the most popular method, due in part to its speed.

Neither of these strategies were designed with regard for cell types with
karyotypic aberrations, most common in cancer cells in culture.  Hi-C is
very sensitive to aneuploidy, copy number variations and translocations.
Actually, these aberrations have so much influence on the outcome that the
artifacts can be used to re-assemble the target genome
\citep{korbel2013genome}.  So far the only attempt to address the issue
was the correction method caICB by \cite{wu2016computational}. However,
caICB applies a chromosome-wide correction, effectively excluding the
numerous cases of partial aneuploidy and regional copy number variations.

Here we propose \textit{OneD}, a method to correct local chromosomal
abnormalities. OneD explicitly models the contribution of known biases via
a generalized additive model. The normalized data is more reproducible
between replicates and across different protocols. Importantly, OneD is
also applicable when cells have a normal karyotype, where it performs as
well as the best normalization methods. Finally, the implementation is
faster than ICE and scales up to 1 kbp resolution with reasonable
computing resources.

%\enlargethispage{12pt}

\begin{methods}

\section{Methods}

\subsection{Model}
\label{sec:model}

The most common representation of Hi-C data is a contact matrix, obtained
by slicing the genome in $n$ consecutive bins of fixed size (the
resolution) and computing the number of contacts between each pair of
bins. The values are stored in the cells of the contact matrix ($x_{ij}$),
quantifying of the interaction between the tow loci at positions $i$ and
$j$.

Our approach is to model the tally of contacts for each bin, thus reducing
the matrix to a one dimension score (hence the name OneD). We assume that
the total number of contacts per bin ($t_{i}$) can be approximated by a
negative binomial distribution. This choice is sensible because the amount
of contacts is a discrete variable and because the negative binomial
distribution allows for overdispersion. We further assume that the
explicit sources of bias have independent contributions to the mean of the
distribution for a given bin ($\lambda_i$).

Given that this relationship might not be linear (see for instance
Figure~\ref{fig:totals}A), we allowed a smooth representation
using thin plate penalized regression splines \citep{wood2003thin} in a
generalized additive model \citep{wood2011fast}. The model can be
parametrized as

\begin{align*}
t_i &= \sum_j^n{x_{ij}} \sim  NB(\lambda_i, \theta), \\
\log(\lambda_i) &\propto \sum_{k}{f_k(z_k)},
\end{align*}

\noindent
where $x_{ij}$ is the raw number of contacts between bins $i$ and $j$, and
$z_k$ is the additive bias of genomic feature $k$. The smooth functions
$\{f_k(\cdot)\}$ are estimated jointly with the negative binomial
dispersion parameter $\theta$ using the \texttt{mgcv} package
\citep{wood2011fast} of the R software \citep{coreteam2014r}.

Once the parameters of the model are estimated, we rescale the estimated
means $\{\lambda_i\}$ to obtain a correction vector $\{\lambda_i'\}$ that
can be used to compute the corrected counts ($\hat{x}_{ij}$).

\begin{align}
\notag
\lambda_i' &= \frac{\lambda_i}{\sum_j^n{\lambda_j}/n} \\
\label{eq:xhat}
\hat{x}_{ij} &= \frac{x_{ij}}{\sqrt{\lambda_i'\lambda_j'}}.
\end{align}

In line with previous methods
\citep{yaffe2011probabilistic,hu2012hicnorm}, the features
used to fit the model are the local G+C content, read mappability and the 
content and number of restriction sites. The model and the implementation
can be easily extended with any user-provided genomic feature.

\subsection{Data sources}

To test the correction of biases, we gathered a set of
published \citep{ledily2014distinct, encode2012integrated, rao20143d,
stadhouders2017transcription, lin2012global, dixon2012topological} and
unpublished Hi-C data of different cell types and organisms. The details
can be found in Table \ref{tab:samples}.

We used several experiments comprising T47D breast cancer cell
lines (7 samples), K562 leukemia cell lines (4 samples), both with
aberrant karyotypes, and mouse primary B (6 samples ) and ES (7 samples)
cells, both with normal diploid karyotypes. The experiments were carried
out in different laboratories, following either the original Hi-C protocol
\citep{lieberman2009comprehensive} or the newer \textit{in situ} version
\citep{rao20143d}, and using different restriction enzymes (DpnII,
HindIII, MboI and NcoI).

We also used array-based copy-number segmentation of the two cell
lines obtained from COSMIC database \citep{forbes2010cosmic}.
 
\begin{table*}
\processtable{Hi-C data sets used in this study.
\label{tab:samples}}
{\begin{tabular}{ccccccc}
  \toprule
  \textbf{Sample ID} & \textbf{Cell type} & \textbf{Application} &
  \textbf{RE} & \textbf{Sequencing core} & \textbf{Set(s)} &
  \textbf{Source} \\
  \midrule
dc3a1e069\_51720e9cf & T47D & \textit{in situ} Hi-C &
  DpnII & CRG & T47D, K562 & NA \\
b1913e6c1\_51720e9cf & T47D & \textit{in situ} Hi-C &
  DpnII & CRG & T47D & NA \\
dc3a1e069\_ec92aa0bb & T47D & \textit{in situ} Hi-C &
  DpnII & CRG & T47D, K562 & NA \\
HindIII\_T0 & T47D & dilution Hi-C &
  HindIII & CRG & T47D & SRR1054341 \\
NcoI\_T0    & T47D & dilution Hi-C &
  NcoI      & CRG & T47D & SRR1054343 \\
ENCLB758KFU & T47D & dilution Hi-C &
  HindIII   & UMass & T47D & ENCLB758KFU \\
ENCLB183QHG & T47D & dilution Hi-C &
  HindIII   & UMass & T47D & ENCLB183QHG \\
HIC069  & K562 & \textit{in situ} Hi-C &
  MboI & Baylor & T47D, K562 &    SRR1658693 \\
HIC070  & K562 & \textit{in situ} Hi-C &
  MboI & Baylor & T47D, K562 &    SRR1658694 \\
HIC071  & K562 & \textit{in situ} Hi-C &
  MboI & Baylor & K562 & SRR1658695,SRR1658696 \\
HIC074  & K562 & \textit{in situ} Hi-C &
  MboI & Baylor & K562 & SRR1658701,SRR1658702 \\
b7fa2d8db\_bfac48760 & B-cell  & \textit{in situ} Hi-C &
  DpnII & CRG & mm10 & GSE96611 \\
fc3e8b36a\_7bf1bf374 & ES-cell & \textit{in situ} Hi-C &
  DpnII & CRG & mm10 & GSE96611 \\
b7fa2d8db\_7284b867a & B-cell  & \textit{in situ} Hi-C &
  DpnII & CRG & mm10 & GSE96611 \\
fc3e8b36a\_38bfd1b33 & ES-cell & \textit{in situ} Hi-C &
  DpnII & CRG & mm10 & GSE96611 \\
b7fa2d8db\_58e812fc2 & B-cell  & \textit{in situ} Hi-C &
  DpnII & CRG & mm10 & GSE96611 \\
fc3e8b36a\_c990a254e & ES-cell & \textit{in situ} Hi-C &
  DpnII & CRG & mm10 & GSE96611 \\
b7fa2d8db\_73f11d923 & B-cell  & \textit{in situ} Hi-C &
  DpnII & CRG & mm10 & GSE96611 \\
fc3e8b36a\_4bf044f18 & ES-cell & \textit{in situ} Hi-C &
  DpnII & CRG & mm10 & GSE96611 \\
GSM987817 & B-cell  & dilution Hi-C &
  HindIII & UCSC & mm10 & SRR543428-SRR543431 \\
GSM987818 & B-cell  & dilution Hi-C &
  HindIII & UCSC & mm10 & SRR543432-SRR543442 \\
GSM862720 & ES-cell & dilution Hi-C &
  HindIII & UCSC & mm10 & SRR443883-SRR443885 \\
GSM862721 & ES-cell & dilution Hi-C &
  HindIII & UCSC & mm10 & SRR400251-SRR400256 \\
GSM862722 & ES-cell & dilution Hi-C &
  NcoI    & UCSC & mm10 & SRR443886-SRR443888 \\
  \botrule
\end{tabular}}{}
\end{table*}

\subsection{Data processing}

All data were processed though a pipeline based on TADBit
\citep{serra2016structural}. Briefly, after controlling the quality of
fastq files, paired-end reads were mapped in the corresponding reference
genome (hg38 and mm10) taking into account the restriction enzyme site.
Non-informative contacts were removed applying the following TADBit
filters: self-circle, dangling-ends, error, extra dangling-end, duplicated
and random-breaks. For more details, see the methods section of
\cite{stadhouders2017transcription}. In addition, the pipeline is
available from the supplementary material published by
\cite{quilez2017managing}.

We developed the routines contained in the \texttt{oned} R package to
efficiently create sparse representations of contact matrices and further
apply \textit{vanilla}, \textit{ice} and \textit{oned} corrections.
\texttt{HiTC} \citep{servant2012hitc} and \texttt{HiCapp}
\citep{wu2016computational} were used to carry out the \textit{lgf} and
\textit{caib} corrections respectively. All the results are based on a
resolution of 100 kbp, but we found no major differences for different
values (not shown).



\subsection{Comparison of Hi-C matrices}
\label{sec:comp}

There is no universally accepted standard to compare Hi-C matrices. The
simplest metric is the Spearman correlation applied to intra-chromosomal
contacts up to a given distance (5 Mb in what follows). The second option
is to measure the similarity of observed over expected contacts via the
Pearson correlation up to a given distance range. Compared to the first,
this metric gives more weight to changes occuring away from the diagonal.
The third option is to compute a correlation per distance stratum and then
obtain a stratum-adjusted correlation coefficient (SCC) as defined in
\cite{yang2017hicrep}. Finally, the last option, proposed by
\cite{yan2017hicspector} is to measure the Pearson correlation between the
last eigenvectors of the Laplacian of the Hi-C matrix. This approach
borrows the concepts of spectral clustering \citep{von2007tutorial} and
amounts to comparing high level features of the matrix.

We defined three data sets to measure experimental reproducibility after
normalization: The first contained the samples from T47D plus two samples
from K562, the second contained the samples from K562 plus two samples
from T47D, the third contained all the mouse samples (see Table
\ref{tab:samples} for details). Given a set of experiments and a metric,
we first computed all pairwise combinations between experiments and then
classified the comparisons according to the characteristics of each pair
(cell type, protocol, batch, and treatment).

We benchmarked \textbf{\textit{oned}}, against \textbf{\textit{vanilla}},
\textbf{\textit{ice}} \citep{imakaev2012iterative}, \textbf{\textit{caib}}
\citep{wu2016computational} and \textbf{\textit{lgf}}
\citep{hu2012hicnorm, servant2012hitc}. The first three methods correct
biases implicitly, whereas the fourth method does it explicitly.

To measure the gain or loss of similarity upon normalization, we compared
raw matrices to obtain a baseline. The differences with this baseline were
estimated using a linear mixed model fitted with the \texttt{lmer}
function of the \texttt{lme4} R package \citep{bates2015lme4}, where the
fixed effect was the normalization method and the random effect was the
chromosome. Receiver operating characteristic (ROC) curves were then
computed using \texttt{ROCR} package \citep{sing2005rocr}.

\end{methods}




%% --------------- Results --------------- %%

\section{Results}

\subsection{Correction method}

The principle of OneD is to explicitly model Hi-C biases on a single
variable: the total amount of contacts for each bin of the matrix (see
\ref{sec:model}). The reason for this choice of that the total amount of
contacts is approximately proportional to the local copy number. For
instance, a duplicated region in a diploid genome will show on average a
50\% increase in the number of contacts. Discontinuities of the amount of
contacts thus correspond to changes of the copy number.

\begin{figure}[!tp]
\centerline{\includegraphics[width=.45\textwidth]{img/figure1.pdf}}
\caption{A. Non linear relationship between the number of restriction
sites per bin and the total number of contacts per bin in T47D. B. Total
number of contacts per bin in chromosome 17 of T47D. Raw (brown) and
corrected (blue) signals are shown. The region that corresponds to the
first 20 Mbp of the chromosome is present in single copy in this clone of
T47D, explaining that the signal is approximately half compared to the
rest of the chromosome.  Also notice that the raw signal is noisier than
the corrected one.}
\label{fig:totals}
\end{figure}

Other biases affect the total amount of contacts in a countinuous but not
necessarily linear way. Figure~\ref{fig:totals}A shows the relationship
between the amount of contacts and the number of retriction enzyme sites
in T47D, a breast cancer cell line with aberrant and unstable karyotype.
Four clouds are visible. Each corresponds to a copy number between one and
four. In all of them, the relationship flattens as the number of
restriction sites increases. For this reason, OneD fits a non-linear
relationship between the total amount of contacts and the known sources of
bias (by default the G+C content, the number of restriction sites and the
mappability of the reads).

The biases are estimated genome-wide and each cell of the matrix is then
corrected using equation (\ref{eq:xhat}). Note that the corrected amount
of contacts is still proportional to the copy number. The correction thus
represents a more stable and precise estimation of the copy number.
Figure~\ref{fig:totals}B shows the corrected number of contacts along
chromosme 17 of a T47D. OneD greatly reduces the wiggling of the total
amount of contacts.

We tested the validity of this approach against the Catalogue Of Somatic
Mutations In Cancer \citep[COSMIC,][]{forbes2010cosmic}. Figure
\ref{fig:copy_number} shows the Pearson correlation between the corrected
number of contacts and the copy number estimation for both T47D and K562
cell lines. Similar results were obtained using Spearman correlation
(Supplementary Figure 2). All the methods except OneD decrease the
agreement with the copy number because they partially correct this bias.
In contrast, OneD enhances the conformity of the signal with the copy
number. Not correcting for variable copy number at that stage may seem to
defeat the purpose of a normalization method, but we will see below how
this can lead to better performance.


\begin{figure}
	\centerline{\includegraphics[width=.45\textwidth]
{img/copy_number_figure2.pdf}}
	\caption{
    Pearson correlation between total number of contacts per bin and
independent copy number estimation (COSMIC) for each of the methods
compared. Left panel T47D breast cancer cell line, right panel K562
leukemia cell line. The new proposal (in blue) outperforms the rest of
alternatives.  }\label{fig:copy_number}
\end{figure}




\subsection{Aberrant karyotypes}

We first benchmarked the performance of OneD on biological samples with an
aberrant karyotype. A good normalization method should increase the
similarity between biological replicates by reducing irrelevant
experimental variation, such as batch effects, laboratory of origin and
protocol variations. Similarly, a good normalization should decrease the
similarity between samples that received a different treatment in order to
enhance the biological differences.

We assembled two Hi-C data sets obtained from T47D and K562, two cancer
cell lines with aberrant karyotypes. In each set we spiked two
samples from the other cell line (see Table~\ref{tab:samples}) in order to
introduce biological variability. We measured the Pearson correlation of
observed over expected counts to compare matrices before and after
normalization by different methods (see \ref{sec:comp}). This gave an
indication of the impact of a given normalization method. The results are
summarized in Figure~\ref{fig:aberrant}.

The \textit{caib} and \textit{ice} methods increased the similarity
between the different cell lines (Figures~\ref{fig:aberrant}A and
\ref{fig:aberrant}C and Supplementary Figure~3). This is an undesirable
effect, as it obscures the biological variability. In the same vein, these
methods decreased the similarity between samples that received the same
treatment (Figures~\ref{fig:aberrant}A), suggesting that the normalization
process is detrimental to the biological signal in these two cases. The
method \textit{vanilla} followed the same trend but to a lesser extent,
consistent with the fact that it consists of a single \textit{ice}
iteration.

OneD was the only method to increase the similarity between experiments
carried out on the same material but with a different protocol
(Figure~\ref{fig:aberrant}A). In these conditions, \textit{lgf} was
decreasing the similarity. Taken together, the results show that OneD
enhanced biological variation while decreasing experimental variation. 

An important application of normalization methods in experimental setups
is to identify outliers. We thus investigated the capacity of the
different methods to help identify the samples from the other cell type
spiked in the data set. We interpreted the pairwise comparison scores as
classifier scores and summarized the results with a ROC curve
(Figures~\ref{fig:aberrant}B and D).

All the methods, including the absence of normalizaton, succeeded in
recognizing the T47D outliers among the K562 samples, but recognizing the
K562 outliers among the T47D samples proved more challenging. OneD
increased the discrimination power compared to the raw matrices, but all
the other methods decreased it. Actually, they performed little better
than random on this task.

Using the other metrics described in \ref{sec:comp} yielded similar
results (Supplementary Figures 3, 4 and 5). Note that Spearman correlation
of contacts presented the worst performance for all scenarios, and it thus
seems to be a poor choice as a metric to compare HiC matrices.

Taken together, these results show that OneD enhances biological variation
and reduces experimental noise on samples with an aberrant karyotype.


\begin{figure}
\centerline{\includegraphics[width=.50\textwidth]{img/correlation_aberrant_figure3.pdf}}
\caption{
Results of the comparison between samples with aberrant karyotype.  A and
B. Average changes compared to raw on the T47D and K562 sets.  The bars
represent 95\% confidence intervals centered on the mean difference of the
correlation score between a given correction method and the raw data. The
brown dashed line indicates the value of the average score on raw matrices
(set to 0). C and D. ROC curves on the T47D and K562 sets. The areas under
the curve are indicated in the bottom right corner. The color code is the
same as panels A and B. The brown lines correspond to raw matrices.  All
results in this figure are based on Pearson correlations between the
observed over expected counts.  Our method increases reproducibility of
similar samples while being able to discriminate different ones.}
\label{fig:aberrant}
\end{figure}


\subsection{Normal karyotypes}

Regarding cells with diploid genomes, we confirmed that our bias
correction strategy also achieves good results in terms separation between
unrelated and similar samples (Figure \ref{fig:normal} and Supplementary
Figures 6 and 7), increasing the reproducibility across different
experimental protocols for primary B and ES mouse cell samples. Again,
Spearman correlation of contacts revealed as the worst metric.

\begin{figure}
	\centerline{\includegraphics[width=.50\textwidth]{img/correlation_normal_figure4.pdf}}
	\caption{
		Results of the comparison between samples with normal karyotype. A Average difference and 95\% CI between each correction method (Y axis) and the raw data (brown dashed line) for the mm10 sets. B Corresponding ROC curves and AUCs. The introduced strategy does not under perform compared to the alternatives.
	}\label{fig:normal}
\end{figure}

\subsection{Computing resources}

One of the main reasons for the broad usage of the iterative correction \citep{imakaev2012iterative} is the easy and fast implementation, moreover compared to existing explicit methods \citep{servant2012hitc}. Our proposal uses only the total number of contacts per bin instead the full matrix for the model estimation. Thus, it achieves similar computing times that the fastest approaches (Figure \ref{fig:times} A). Yet it scales with increasing resolutions (decreasing bin size) (Figure \ref{fig:times} B).

\begin{figure}
	\centerline{\includegraphics[width=.35\textwidth]{img/times_sina_figure5.pdf}}
	\caption{
		Computing time (Y axis, log scale) of all the bias correction methods used. Each dot corresponds to one sample. The only method faster than ours under performs in all sample comparisons.
	}\label{fig:times}
\end{figure}

\section{Discussion and Conclusions}


\section*{Acknowledgements}

We would like to thank all members of the four labs involved in the 4DGenome Synergy project for the fruitful discussions during project meetings. EV wants to acknowledge specially the members of Miguel Beato's lab for their insights during lab meetings.

\section*{Funding}

This work was supported by the Spanish Ministry of Economy and
Competitiveness, ‘Centro de Excelencia Severo Ochoa 2013-2017’,
SEV-2012-0208, ERC Synergy Grant 609989 (GF) and...
\vspace*{-12pt}

\bibliographystyle{natbib}
\bibliography{references}

\end{document}
